{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Some important function\n",
    "def MAPE(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    %Error compares true value with predicted value. Lower the better. Use this along with rmse(). If the series has \n",
    "    outliers, compare/select model using MAPE instead of rmse()\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true, y_pred = numpy.array(y_true), numpy.array(y_pred)\n",
    "    return numpy.mean(numpy.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def accuracy(y1,y2):\n",
    "    \n",
    "    accuracy_df=pandas.DataFrame()\n",
    "    \n",
    "    rms_error = numpy.round(rmse(y1, y2),4)\n",
    "    \n",
    "    map_error = numpy.round(MAPE(y1,y2),4)\n",
    "           \n",
    "    accuracy_df=accuracy_df.append({\"RMSE\":rms_error, \"%MAPE\": map_error}, ignore_index=True)\n",
    "    \n",
    "    return accuracy_df\n",
    "\n",
    "\n",
    "### Holt-Winter's Grid Search\n",
    "def HWGrid(train, test, seasonal_periods, trend = ['add','mul'], seasonal= ['add','mul'],use_boxcox =[False, True, 'log'] ):\n",
    "    \"\"\"\n",
    "    # copied from a blog @Deepak\n",
    "    Author: Sandeep Pawar twitter: @PawarBI\n",
    "    Functions returns a dataframe with parameters of the Holt-Winter's method and corresponding train & test evaluation scores. \n",
    "    It also does a quick check of the residuals using Ljung-Box test and Shapiro test for normality. \n",
    "    Residuals must be uncorrelated. \n",
    "    \n",
    "    train: (pandas series)\n",
    "        -  Training data\n",
    "        \n",
    "    test: (pandas series)\n",
    "        -  Test data\n",
    "    \n",
    "    Seasonal_periods: int\n",
    "        - No of seasonas in the time period. e.g. 4 for Quarterly, 12 for Monthly, 52 for Weekly data\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    import itertools\n",
    "    damped     = [False, True]\n",
    "\n",
    "    params = itertools.product(trend,seasonal,damped,use_boxcox)\n",
    "\n",
    "    result_df = pandas.DataFrame(columns=['Trend', 'Seasonal', 'Damped', 'BoxCox','AICc Train',  \n",
    "                                      '%MAPE_Train', 'RMSE_Train', '%MAPE_Test', \n",
    "                                      'RMSE_Test', \"Resid_LJ\", \"Resid_Norm\",\"Resid_mean\" ])\n",
    "    \n",
    "    \n",
    "    for trend,seasonal,damped,use_boxcox in params:\n",
    "    \n",
    "            model = ExponentialSmoothing(train, \n",
    "                                     trend=trend,\n",
    "                                     damped=damped,\n",
    "                                     seasonal=seasonal,\n",
    "                                     seasonal_periods=seasonal_periods).fit(use_boxcox=use_boxcox)\n",
    "    \n",
    "    \n",
    "            \n",
    "            mape1=MAPE(train,model.fittedvalues) \n",
    "            rmse1=rmse(train,model.fittedvalues)\n",
    "\n",
    "            mape2=MAPE(test,model.forecast(len(test))) \n",
    "            rmse2=rmse(test,model.forecast(len(test)))\n",
    "\n",
    "            aicc1 = model.aicc.round(1)\n",
    "\n",
    "               \n",
    "    \n",
    "            lj_p_val = numpy.mean(ljung(x=model.resid, lags=10)[1])\n",
    "            norm_p_val =  jb(model.resid)[1]#shapiro(model.resid)[1]\n",
    "    \n",
    "            lj = \"Uncorrelated\" if lj_p_val > 0.05 else \"Correlated\"\n",
    "            norm = \"Normal\" if norm_p_val > 0.05 else \"Non-Normal\"\n",
    "            \n",
    "    \n",
    "            result_df = result_df.append({'Trend':trend       ,\n",
    "                              'Seasonal': seasonal            ,\n",
    "                              'Damped':damped                 ,\n",
    "                              'BoxCox':use_boxcox             ,\n",
    "                              '%MAPE_Train':numpy.round(mape1,2) ,\n",
    "                              'RMSE_Train':numpy.round(rmse1,1)  ,\n",
    "                              'AICc Train':aicc1              ,\n",
    "                              '%MAPE_Test':numpy.round(mape2,2)  ,\n",
    "                              'RMSE_Test':numpy.round(rmse2,1)   ,\n",
    "                              'Resid_LJ' :lj                  ,\n",
    "                              'Resid_Norm':norm               ,\n",
    "                              'Resid_mean':numpy.round(model.resid.mean(),1)} , ignore_index=True, sort=False)\n",
    "    \n",
    "    \n",
    "    return result_df.sort_values(by=[\"RMSE_Test\", \"%MAPE_Test\",\"RMSE_Train\",\"%MAPE_Train\"])\n",
    "\n",
    "\n",
    "def hw_cv(series, seasonal_periods, initial_train_window, test_window):\n",
    "    \n",
    "    from statsmodels.tools.eval_measures import rmse\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    \"\"\"\n",
    "     Author: Sandeep Pawar\n",
    "     Date: 4/15/2020\n",
    "     Ver: 1.0\n",
    "     \n",
    "     Returns Rolling and Expanding cross-validation scores (avg rmse), along with model paramters\n",
    "     for Triple Exponential Smoothing method. Expanding expands the training set each time by adding one observation, \n",
    "     while rolling slides the training and test by one observation each time. \n",
    "     \n",
    "     Output shows parameters used and Rolling & Expanding cv scores. Output is in below order:\n",
    "          1. Trend 2. Seasonal 3. Damped 4. use_boxcox 5. Rolling cv 6. Expanding cv \n",
    "     \n",
    "     Requirements: Pandas, Numpy, Statsmodels, itertools, rmse \n",
    "     \n",
    "     series: Pandas Series\n",
    "             Time series \n",
    "     \n",
    "     seasonal_periods: int\n",
    "             No of seasonal periods in a full cycle (e.g. 4 in quarter, 12 in monthly, 52 in weekly data)\n",
    "             \n",
    "     initial_train_window: int\n",
    "             Minimum training set length. Recommended to use minimum 2 * seasonal_periods\n",
    "     \n",
    "     test_window: int\n",
    "             Test set length. Recommended to use equal to forecast horizon\n",
    "             \n",
    "     e.g. hw_cv(ts[\"Sales\"], 4, 12, 6 )\n",
    "          Output: add add False False    R: 41.3   ,E: 39.9\n",
    "\n",
    "          \n",
    "     Note: This function can take anywhere from 5-15 min to run full output        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def expanding_tscv(series,trend,seasonal,seasonal_periods,damped,boxcox,initial_train_window, test_window):\n",
    "        i =  0\n",
    "        x = initial_train_window\n",
    "        t = test_window\n",
    "        errors_roll=[]\n",
    "\n",
    "        while (i+x+t) <len(series):\n",
    "            train_ts=series[:(i+x)].values\n",
    "            test_ts= series[(i+x):(i+x+t)].values\n",
    "            model_roll = ExponentialSmoothing(train_ts,\n",
    "                                         trend=trend,\n",
    "                                         seasonal=seasonal,\n",
    "                                         seasonal_periods=seasonal_periods,\n",
    "                                         damped=damped).fit(use_boxcox=boxcox)\n",
    "\n",
    "            fcast = model_roll.forecast(t)\n",
    "\n",
    "            error_roll = rmse(test_ts, fcast)\n",
    "\n",
    "            errors_roll.append(error_roll)\n",
    "\n",
    "            i=i+1\n",
    "\n",
    "\n",
    "        return numpy.mean(errors_roll).round(1)\n",
    "\n",
    "    def rolling_tscv(series,trend,seasonal,seasonal_periods,damped,boxcox,initial_train_window, test_window):\n",
    "        i =  0\n",
    "        x = initial_train_window\n",
    "        t = test_window\n",
    "        errors_roll=[]\n",
    "\n",
    "        while (i+x+t) <len(series):\n",
    "            train_ts=series[(i):(i+x)].values\n",
    "            test_ts= series[(i+x):(i+x+t)].values\n",
    "            model_roll = ExponentialSmoothing(train_ts,\n",
    "                                         trend=trend,\n",
    "                                         seasonal=seasonal,\n",
    "                                         seasonal_periods=seasonal_periods,\n",
    "                                         damped=damped).fit(use_boxcox=boxcox)\n",
    "\n",
    "            fcast = model_roll.forecast(t)\n",
    "\n",
    "            error_roll = rmse(test_ts, fcast)\n",
    "\n",
    "            errors_roll.append(error_roll)\n",
    "\n",
    "            i=i+1\n",
    "\n",
    "   \n",
    "        return numpy.mean(errors_roll).round(1)\n",
    "   \n",
    "    trend      = ['add','mul']\n",
    "    seasonal   = ['add','mul']\n",
    "    damped     = [False, True]\n",
    "    use_boxcox = [False, True, 'log']\n",
    "\n",
    "    params = itertools.product(trend,seasonal,damped,use_boxcox)\n",
    "\n",
    "    for trend,seasonal,damped,use_boxcox in params:\n",
    "        r=rolling_tscv(data[\"Sales\"], trend, seasonal, 4, damped, use_boxcox, 12,4)\n",
    "        e=expanding_tscv(data[\"Sales\"], trend, seasonal, 4, damped, use_boxcox, 12,4)\n",
    "        result = print(trend, seasonal, damped, use_boxcox,\"   R:\", r,\"  ,E:\", e)\n",
    "          \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def residcheck(residuals, lags):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to check if the residuals are white noise. Ideally the residuals should be uncorrelated, zero mean, \n",
    "    constant variance and normally distributed. First two are must, while last two are good to have. \n",
    "    If the first two are not met, we have not fully captured the information from the data for prediction. \n",
    "    Consider different model and/or add exogenous variable. \n",
    "    \n",
    "    If Ljung Box test shows p> 0.05, the residuals as a group are white noise. Some lags might still be significant. \n",
    "    \n",
    "    Lags should be min(2*seasonal_period, T/5)\n",
    "    \n",
    "    plots from: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    \n",
    "    \"\"\"\n",
    "    resid_mean = numpy.mean(residuals)\n",
    "    lj_p_val = numpy.mean(ljung(x=residuals, lags=lags)[1])\n",
    "    norm_p_val =  jb(residuals)[1]\n",
    "    adfuller_p = adfuller(residuals)[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    layout = (2, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2);\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0));\n",
    "    kde_ax = plt.subplot2grid(layout, (1, 1));\n",
    "\n",
    "    residuals.plot(ax=ts_ax)\n",
    "    plot_acf(residuals, lags=lags, ax=acf_ax);\n",
    "    sns.kdeplot(residuals);\n",
    "    #[ax.set_xlim(1.5) for ax in [acf_ax, kde_ax]]\n",
    "    sns.despine()\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    print(\"** Mean of the residuals: \", numpy.around(resid_mean,2))\n",
    "    \n",
    "    print(\"\\n** Ljung Box Test, p-value:\", numpy.around(lj_p_val,3), \"(>0.05, Uncorrelated)\" if (lj_p_val > 0.05) else \"(<0.05, Correlated)\")\n",
    "    \n",
    "    print(\"\\n** Jarque Bera Normality Test, p_value:\", numpy.around(norm_p_val,3), \"(>0.05, Normal)\" if (norm_p_val>0.05) else \"(<0.05, Not-normal)\")\n",
    "    \n",
    "    print(\"\\n** AD Fuller, p_value:\", numpy.around(adfuller_p,3), \"(>0.05, Non-stationary)\" if (adfuller_p > 0.05) else \"(<0.05, Stationary)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return ts_ax, acf_ax, kde_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
